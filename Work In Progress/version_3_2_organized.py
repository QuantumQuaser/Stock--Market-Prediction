# -*- coding: utf-8 -*-
"""version_3.2_organized.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QbhaAlu-ElJLkuSbgFf0-uEmNWjMqerV
"""

pip install feedparser textblob

# Required for data collection and analysis
import yfinance as yf
import pandas as pd
import numpy as np

# For sentiment analysis
import feedparser
from textblob import TextBlob

# Machine learning tools
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score
from sklearn.preprocessing import StandardScaler

"""**2. Function Definitions for Data Collection and Analysis**"""

# Function to download stock data from Yahoo Finance
def download_stock_data(ticker, start_date, end_date):
    return yf.download(ticker, start=start_date, end=end_date)

# Functions to fetch news, analyze sentiment, and get aggregated news sentiment
def fetch_news(stock_name):
    feed_url = f'https://news.google.com/rss/search?q={stock_name}+when:7d&hl=en-IN&gl=IN&ceid=IN:en'
    news_feed = feedparser.parse(feed_url)
    return [(entry.title, entry.link, entry.published) for entry in news_feed.entries]

def analyze_sentiment(text):
    analysis = TextBlob(text)
    return analysis.sentiment.polarity

def get_stock_news_sentiment(stock_names):
    all_news_sentiments = []
    for stock in stock_names:
        news_items = fetch_news(stock)
        for title, link, published in news_items:
            sentiment_score = analyze_sentiment(title)
            all_news_sentiments.append([stock, title, link, published, sentiment_score])
    return pd.DataFrame(all_news_sentiments, columns=['Stock', 'Title', 'Link', 'Published', 'Sentiment'])

"""**3. Download Stock Data**"""

# List of stock tickers including Nifty 50 index
stocks = ['BAJFINANCE.NS', 'HDFCAMC.NS', 'ASIANPAINT.NS', 'TCS.NS', 'DRREDDY.NS', '^NSEI']
start_date = '2012-01-01'
end_date = '2023-01-26'

# Download stock data for each ticker
stock_data = {stock: download_stock_data(stock, start_date, end_date) for stock in stocks}

"""**4. Sentiment Analysis and Technical Indicators Calculation**"""

# Function definitions for technical indicators
def calculate_rsi(data, window=14):
    # Calculation of Relative Strength Index (RSI)
    delta = data['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
    rs = gain / loss
    rsi = 100 - (100 / (1 + rs))
    return rsi.fillna(0)

def calculate_sma(data, window=10):
    # Calculation of Simple Moving Average (SMA)
    return data['Close'].rolling(window=window).mean()

def calculate_ema(data, window=10):
    # Calculation of Exponential Moving Average (EMA)
    return data['Close'].ewm(span=window, adjust=False).mean()

# Analyze sentiment for each stock and calculate technical indicators
for ticker in stocks[:-1]:  # Exclude Nifty 50 from sentiment analysis
    df = stock_data[ticker]
    df['RSI'] = calculate_rsi(df)
    df['SMA'] = calculate_sma(df)
    df['EMA'] = calculate_ema(df)
    news_items = fetch_news(ticker)
    sentiment_scores = [analyze_sentiment(title) for title, _, _ in news_items]
    avg_sentiment_score = np.mean(sentiment_scores) if sentiment_scores else 0
    df['Avg_Sentiment'] = avg_sentiment_score
    stock_data[ticker] = df

"""**5. Merge Nifty 50 Data and Calculate Weekly Returns**"""

# Fetch Nifty 50 data and calculate its technical indicators
nifty_data = download_stock_data('^NSEI', start_date, end_date)
nifty_data['RSI_Nifty'] = calculate_rsi(nifty_data)
nifty_data['SMA_Nifty'] = calculate_sma(nifty_data)
nifty_data['EMA_Nifty'] = calculate_ema(nifty_data)

# Merge Nifty 50 indicators with each stock's data
for ticker in stocks[:-1]:
    stock_data[ticker] = stock_data[ticker].merge(nifty_data[['RSI_Nifty', 'SMA_Nifty', 'EMA_Nifty']], left_index=True, right_index=True, how='left')

# Calculate weekly returns for each stock
def calculate_weekly_return(data):
    return data['Close'].pct_change(periods=5)  # 5 trading days in a week

for ticker in stocks[:-1]:
    stock_data[ticker]['Week'] = stock_data[ticker].index.to_period('W')
    stock_data[ticker]['Weekly_Return'] = calculate_weekly_return(stock_data[ticker])
    stock_data[ticker]['Ticker'] = ticker

"""**6. Determine the Best-Performing Stock Each Week**"""

# Combine data for all stocks and drop NaNs in 'Weekly_Return'
combined_data = pd.concat([stock_data[ticker] for ticker in stocks[:-1]])
combined_data.dropna(subset=['Weekly_Return'], inplace=True)

# Group by week and ticker, then identify the best-performing stock each week
weekly_returns = combined_data.groupby(['Week', 'Ticker'])['Weekly_Return'].mean().reset_index()
weekly_best = weekly_returns.loc[weekly_returns.groupby('Week')['Weekly_Return'].idxmax()]
weekly_best.rename(columns={'Ticker': 'Best_Ticker', 'Weekly_Return': 'Best_Weekly_Return'}, inplace=True)

# Merge this information back to the combined data
combined_data = pd.merge(combined_data, weekly_best[['Week', 'Best_Ticker']], on='Week', how='left')
combined_data['Target'] = (combined_data['Ticker'] == combined_data['Best_Ticker']).astype(int)

"""**7. Preparing the Data for Machine Learning**"""

# Create a mapping from tickers to numerical labels
target_mapping = {ticker: idx for idx, ticker in enumerate(stocks[:-1])}
combined_data['Target'] = combined_data['Ticker'].map(target_mapping)

# Feature scaling
scaler = StandardScaler()
features = ['RSI', 'SMA', 'EMA', 'Avg_Sentiment', 'RSI_Nifty', 'SMA_Nifty', 'EMA_Nifty']
combined_data[features] = scaler.fit_transform(combined_data[features])

# Split the data into training and testing sets
X = combined_data[features].fillna(0)
y = combined_data['Target'].fillna(False)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

"""**8. Model Training and Evaluation**"""

# Train a Random Forest Classifier
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Predict and evaluate the model
predictions = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, predictions))

# Reverse mapping from numerical labels to tickers for interpretation
inverse_target_mapping = {v: k for k, v in target_mapping.items()}
target_names = [inverse_target_mapping[label] for label in combined_data['Target'].unique()]
print(classification_report(y_test, predictions, labels=combined_data['Target'].unique(), target_names=target_names))