{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QE_gpKidJCrz"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_stock_data(ticker, start_date, end_date):\n",
        "    return yf.download(ticker, start=start_date, end=end_date)\n",
        "\n",
        "stocks = ['BAJFINANCE.NS', 'HDFCAMC.NS', 'ASIANPAINT.NS', 'TCS.NS', 'DRREDDY.NS', '^NSEI']  # ^NSEI for Nifty 50\n",
        "start_date = '2012-01-01'\n",
        "end_date = '2023-01-26'\n",
        "\n",
        "stock_data = {stock: download_stock_data(stock, start_date, end_date) for stock in stocks}"
      ],
      "metadata": {
        "id": "tBYfTzxwJMKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install feedparser textblob\n"
      ],
      "metadata": {
        "id": "buRnSULELezX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import feedparser\n",
        "from textblob import TextBlob\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Nuyoie4FLa4C"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_news(stock_name):\n",
        "    feed_url = f'https://news.google.com/rss/search?q={stock_name}+when:7d&hl=en-IN&gl=IN&ceid=IN:en'\n",
        "    news_feed = feedparser.parse(feed_url)\n",
        "    return [(entry.title, entry.link, entry.published) for entry in news_feed.entries]\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    analysis = TextBlob(text)\n",
        "    return analysis.sentiment.polarity\n",
        "\n",
        "def get_stock_news_sentiment(stock_names):\n",
        "    all_news_sentiments = []\n",
        "    for stock in stock_names:\n",
        "        news_items = fetch_news(stock)\n",
        "        for title, link, published in news_items:\n",
        "            sentiment_score = analyze_sentiment(title)  # Analyzing sentiment of the news title\n",
        "            all_news_sentiments.append([stock, title, link, published, sentiment_score])\n",
        "    return pd.DataFrame(all_news_sentiments, columns=['Stock', 'Title', 'Link', 'Published', 'Sentiment'])"
      ],
      "metadata": {
        "id": "4FDweEUaLjq6"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of stocks\n",
        "stocks = ['BAJFINANCE', 'HDFCAMC', 'ASIANPAINT', 'TCS', 'DRREDDY']"
      ],
      "metadata": {
        "id": "adhI9FWlLsGX"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get news sentiment\n",
        "news_sentiment = get_stock_news_sentiment(stocks)\n",
        "print(news_sentiment)"
      ],
      "metadata": {
        "id": "sQDsrr4gLwMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from textblob import TextBlob\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "MR0mpdryN3X1"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_stock_data(ticker, start_date, end_date):\n",
        "    return yf.download(ticker, start=start_date, end=end_date)\n",
        "\n",
        "def calculate_rsi(data, window=14):\n",
        "    delta = data['Close'].diff()\n",
        "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
        "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
        "    rs = gain / loss\n",
        "    rsi = 100 - (100 / (1 + rs))\n",
        "    return rsi.fillna(0)\n",
        "\n",
        "def calculate_sma(data, window=10):\n",
        "    return data['Close'].rolling(window=window).mean()\n",
        "\n",
        "def calculate_ema(data, window=10):\n",
        "    return data['Close'].ewm(span=window, adjust=False).mean()\n",
        "\n",
        "def perform_sentiment_analysis(text):\n",
        "    return TextBlob(text).sentiment.polarity\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jFUB1g89N6Ys"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tickers = ['BAJFINANCE.NS', 'HDFCAMC.NS', 'ASIANPAINT.NS', 'TCS.NS', 'DRREDDY.NS']\n",
        "start_date = '2012-01-01'\n",
        "end_date = '2023-12-26'\n",
        "\n",
        "stock_data = {}\n",
        "for ticker in tickers:\n",
        "    df = get_stock_data(ticker, start_date, end_date)\n",
        "    df['RSI'] = calculate_rsi(df)\n",
        "    df['SMA'] = calculate_sma(df)\n",
        "    df['EMA'] = calculate_ema(df)\n",
        "    stock_data[ticker] = df\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32LuX39EOI59",
        "outputId": "f1bfa925-2419-4b17-f3ec-4a10ec3e529b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for ticker in stock_data:\n",
        "    # Fetch news and analyze sentiment\n",
        "    news_items = fetch_news(ticker)\n",
        "    sentiment_scores = [analyze_sentiment(title) for title, _, _ in news_items]\n",
        "    avg_sentiment_score = np.mean(sentiment_scores) if sentiment_scores else 0\n",
        "\n",
        "    # Add Avg_Sentiment to the DataFrame\n",
        "    stock_data[ticker]['Avg_Sentiment'] = avg_sentiment_score\n",
        "\n"
      ],
      "metadata": {
        "id": "xL3ve-HgR9OD"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_data = pd.concat(stock_data.values())\n",
        "scaler = StandardScaler()\n",
        "features = ['RSI', 'SMA', 'EMA', 'Avg_Sentiment']\n",
        "combined_data[features] = scaler.fit_transform(combined_data[features])\n",
        "\n",
        "combined_data['Target'] = combined_data['Close'].shift(-5) > combined_data['Close']\n",
        "X = combined_data[features].fillna(0)\n",
        "y = combined_data['Target'].fillna(False)\n"
      ],
      "metadata": {
        "id": "k9jq0SMQSTDv"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print(classification_report(y_test, predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luqm7ruAT_i-",
        "outputId": "f7932419-7824-40e4-e150-5451502a53cf"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.58      0.53      0.56      1764\n",
            "        True       0.65      0.69      0.67      2180\n",
            "\n",
            "    accuracy                           0.62      3944\n",
            "   macro avg       0.62      0.61      0.61      3944\n",
            "weighted avg       0.62      0.62      0.62      3944\n",
            "\n"
          ]
        }
      ]
    }
  ]
}